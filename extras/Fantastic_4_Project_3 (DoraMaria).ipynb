{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q91KqmCRu64D"
   },
   "source": [
    "# **Project 3: Hot Dog Not Dog**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount the shared Google Drive folder\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "# Get the folder ID from the URL\n",
    "folder_id = '1RdqEY7EuOLFJiNlVzFkAfuFKJ8si82bb'\n",
    "\n",
    "# Construct the path to the shared folder\n",
    "shared_folder_path = '/content/gdrive/My Drive/' + folder_id\n",
    "\n",
    "# Change the current working directory to the shared folder\n",
    "%cd '{shared_folder_path}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8U3DUa3eNsT"
   },
   "source": [
    "## **Import the necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dVzeuF3eQx1"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# scikit-learn modules\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Library for randomly selecting data points\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lsux2ZwyTTR"
   },
   "source": [
    "## **Load the dataset**\n",
    "\n",
    "- Let us now load the dataset that is available as a .h5 file.\n",
    "- Split the data into the train and the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BApX9qgNsqV0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a Function to Load Images and Labels\n",
    "# This function walks through the directory structure, loads the images, and extracts labels from the directory names:\n",
    "\n",
    "def load_images_and_labels(base_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Walk through the directory\n",
    "    for dirpath, dirnames, filenames in os.walk(base_dir):\n",
    "        # Extract the label from the last part of dirpath\n",
    "        label = os.path.basename(dirpath)\n",
    "        \n",
    "        for file in filenames:\n",
    "            # Check for .jpg files\n",
    "            if file.endswith('.jpg'):\n",
    "                file_path = os.path.join(dirpath, file)\n",
    "                # Open and convert the image to RGB\n",
    "                image = Image.open(file_path).convert('RGB')\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the Function with the Directory\n",
    "base_directory = ''\n",
    "images, labels = load_images_and_labels(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a random image from the list to ensure the import was successful\n",
    "images[40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVe0CYpUgj7w"
   },
   "source": [
    "Check the number of images in the training and the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3lwKpOefkpA"
   },
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akTUOfLlgwoM"
   },
   "source": [
    "**Observation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxODV6HKykuc"
   },
   "source": [
    "## **Visualizing images**\n",
    "\n",
    "- Use X_train to visualize the first 10 images.\n",
    "- Use Y_train to print the first 10 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bvsc8ytHsqWD"
   },
   "outputs": [],
   "source": [
    "# Visualizing the first 10 images in the dataset and printing their classification labels\n",
    "\n",
    "categories = np.unique(y_train)\n",
    "\n",
    "# Set the number of columns and rows for the grid\n",
    "cols = 3\n",
    "rows = 3\n",
    "\n",
    "# Create a 3x3 grid for displaying the first 9 images\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        if i * cols + j >= 9:  # Display only the first 9 images\n",
    "            break\n",
    "        random_index = i * cols + j\n",
    "        ax = plt.subplot(rows, cols, i * cols + j + 1)\n",
    "        ax.imshow(X_train[random_index], cmap='gray')\n",
    "        ax.set_title(categories[y_train[random_index]])\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzoyeXHOy80N"
   },
   "source": [
    "## **Data preparation**\n",
    "\n",
    "- Print the shape and the array of pixels for the first image in the training dataset.\n",
    "- Normalize the train and the test dataset by dividing by 255.\n",
    "- Print the new shapes of the train and the test dataset.\n",
    "- One-hot encode the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqndzQXng9rL"
   },
   "outputs": [],
   "source": [
    "# Get all the sizes into a list, then convert to a set\n",
    "sizes = set([img.size for img in images])\n",
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of sets of different sizes. \n",
    "len(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize all images\n",
    "\n",
    "def resize_images(images, new_size=(256, 256)):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        # Resize the image using the LANCZOS filter for high-quality downsampling\n",
    "        img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "        img = img.convert('RGB')\n",
    "        resized_images.append(img)\n",
    "    return resized_images\n",
    "\n",
    "# Apply the resize function\n",
    "images_resized = resize_images(images, new_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the resizing of all images\n",
    "# Get all the sizes into a list, then convert to a set\n",
    "sizes = set([img.size for img in images_resized])\n",
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all images to floating point numpy arrays\n",
    "float_images = [np.array(img).astype(np.float32) for img in images_resized]\n",
    "\n",
    "# Display the pixel values of the first image\n",
    "print(\"Pixel Values:\")\n",
    "print(float_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4CQkKtQ0XII"
   },
   "source": [
    "### **Normalize the train and the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_yUUTp_mUzB"
   },
   "outputs": [],
   "source": [
    "# Normalizing the image pixel inputs\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first normalized training image\n",
    "print('Test Dataset:', X_test.shape, y_test.shape)\n",
    "print('Training Dataset:', X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first normalized testing image and its pixel values\n",
    "print(\"Shape of the first normalized testing image:\", X_test[0].shape)\n",
    "print(\"Pixel values of the first normalized testing image:\")\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uLxXBpz81vk"
   },
   "source": [
    "### **Encode Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zL0lYER4sqWw"
   },
   "outputs": [],
   "source": [
    "# Encode the y data\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder and return encoded labels\n",
    "encoded_labels = label_encoder.fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViqPOTquCF76"
   },
   "source": [
    "**Observation:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 500 images of \"hotdog\" and 500 images of \"not hotdog,\" we have a decently sized dataset to start with, especially considering the balance between the classes. The need to augment the dataset to increase its size depends on several factors:\n",
    "\n",
    "1. **Model Complexity**\n",
    "If you are using a complex model or deep neural network, these typically require large amounts of data to generalize well without overfitting. In such cases, even a dataset of 1,000 images might be insufficient, and data augmentation could help by artificially expanding the diversity and size of your training data.\n",
    "\n",
    "2. **Performance Goals**\n",
    "Consider your performance metrics and goals. If initial training results are not satisfactory or if the model performs well on training data but poorly on validation data (a sign of overfitting), then data augmentation might be necessary to improve the modelâ€™s ability to generalize.\n",
    "\n",
    "3. **Variability in Data**\n",
    "Data augmentation is particularly useful when you need the model to be robust against variations in inputs that are not well-represented in your dataset. For example, if your \"hotdog\" images are all taken under similar lighting conditions or from similar angles, your model might not perform well when presented with \"hotdog\" images under different conditions. Augmenting data to include transformed images (e.g., different rotations, lighting conditions, and crops) can help the model learn to recognize the key features of \"hotdog\" and \"not hotdog\" under a broader range of conditions.\n",
    "\n",
    "4. **Computational Resources**\n",
    "More data typically requires more computational power and longer training times. If resources are limited, you might start with your existing dataset to see how well you can optimize the model and consider augmentation if improvements are needed and computationally feasible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentation to the whole training dataset\n",
    "# Create an ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,      # Random rotation (degrees)\n",
    "    width_shift_range=0.1,  # Random horizontal shift\n",
    "    height_shift_range=0.1, # Random vertical shift\n",
    "    shear_range=0.2,        # Shear intensity\n",
    "    zoom_range=0.2,         # Random zoom\n",
    "    horizontal_flip=True,   # Random horizontal flip\n",
    "    vertical_flip=False,    # No vertical flip for face images\n",
    "    fill_mode='nearest'     # Fill mode for handling newly created pixels\n",
    ")\n",
    "\n",
    "# Create variables to hold the X and y training data\n",
    "X_train_aug = []\n",
    "y_train_aug = []\n",
    "\n",
    "# Loop through all the images.\n",
    "for i in range(len(X_train)):\n",
    "    # Select the image\n",
    "    img = X_train[i]\n",
    "    # Select the label from the training data\n",
    "    label = y_train[i]\n",
    "    \n",
    "    # Add a channel dimension for grayscale images\n",
    "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "\n",
    "    # Ensure that the input data has the correct shape\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Add 5 images for every original image\n",
    "    for j in range(5):\n",
    "        # Append a new image to the X list\n",
    "        X_train_aug.append(datagen.flow(img, batch_size=1).next()[0])\n",
    "        # Append the label for the original image to the y list\n",
    "        y_train_aug.append(label)\n",
    "\n",
    "# Print the length of each list\n",
    "print(len(X_train_aug))\n",
    "print(len(y_train_aug))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape test data for the model\n",
    "X_test_np = []\n",
    "for img in X_test:\n",
    "    # Add a channel dimension for grayscale images\n",
    "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "    # Append the image to the list\n",
    "    X_test_np.append(img)\n",
    "\n",
    "# Convert to numpy array\n",
    "X_test_np = np.array(X_test_np)\n",
    "\n",
    "# Check the shape of the first image\n",
    "X_test_np[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yH-gVrzuByNA"
   },
   "source": [
    "## **Model Building**\n",
    "\n",
    "**ANN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcKRwrGn0XIL"
   },
   "outputs": [],
   "source": [
    "### Fix the seed for random number generators\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJDUoaEj1d6e"
   },
   "source": [
    "### **Model Architecture**\n",
    "- Write a function that returns a sequential model with the following architecture:\n",
    " - First hidden layer with **64 nodes and the relu activation** and the **input shape = (1024, )**\n",
    " - Second hidden layer with **32 nodes and the relu activation**\n",
    " - Output layer with **activation as 'softmax' and number of nodes equal to the number of classes, i.e., 10**\n",
    " - Compile the model with the **loss equal to categorical_crossentropy, optimizer equal to Adam(learning_rate = 0.001), and metric equal to 'accuracy'**. Do not fit the model here, just return the compiled model.\n",
    "- Call the nn_model_1 function and store the model in a new variable. \n",
    "- Print the summary of the model.\n",
    "- Fit on the train data with a **validation split of 0.2, batch size = 128, verbose = 1, and epochs = 20**. Store the model building history to use later for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A48z6ucF0XIP"
   },
   "source": [
    "### **Build and train an ANN model as per the above mentioned architecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cmi81Gr5sqW-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "from transformers import ViTFeatureExtractor\n",
    "\n",
    "# Initialize the feature extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "# Prepare the images for the transformer model\n",
    "def prepare_images_for_vit(images):\n",
    "    return [feature_extractor(images[i], return_tensors='tf').pixel_values[0] for i in range(len(images))]\n",
    "\n",
    "# Prepare training and testing datasets\n",
    "X_train_vit = prepare_images_for_vit(X_train)\n",
    "X_test_vit = prepare_images_for_vit(X_test)\n",
    "\n",
    "# Load the pre-trained Vision Transformer model\n",
    "vit_model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=2)\n",
    "\n",
    "# Compile the model\n",
    "vit_model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the transformer model on the training data\n",
    "history_vit = vit_model.fit(X_train_vit, y_train, epochs=5, batch_size=16, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = vit_model.evaluate(X_test_vit, y_test)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model Architecture\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=0.001),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Assuming input_shape is (256, 256, 3) for RGB images and num_classes is 2 for 'hotdog' and 'not hotdog'\n",
    "cnn_model = build_cnn_model((256, 256, 3), 2)\n",
    "cnn_model.summary()\n",
    "\n",
    "# Fit the CNN model on the training data\n",
    "history_cnn = cnn_model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training-images/\n",
    "    hotdog/\n",
    "    pineapple/\n",
    "    pizza/\n",
    "    hamburger/\n",
    "\n",
    "validation_images/\n",
    "    hotdog/\n",
    "    pineapple/\n",
    "    pizza/\n",
    "    hamburger/\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the model\n",
    "def build_multivariate_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        # Convolutional base\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Assuming input_shape is (150, 150, 3) for RGB images and num_classes is 4\n",
    "model = build_multivariate_model((150, 150, 3), 4)\n",
    "model.summary()\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Note: The validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'training-images',  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')  # Since we use categorical_crossentropy loss, we need categorical labels\n",
    "\n",
    "# Flow validation images in batches of 32 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'validation_images',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=15,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)  # 800 images = batch_size * steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(validation_generator)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeF8XSWz0XIU"
   },
   "source": [
    "### **Plot the Training and Validation Accuracies and write down your Observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lt77zgGMP4yw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGBbQpLONX7k"
   },
   "source": [
    "**Observations:_______**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0qgLMBZm5-K"
   },
   "source": [
    "Let's build one more model with higher complexity and see if we can improve the performance of the model. \n",
    "\n",
    "First, we need to clear the previous model's history from the Keras backend. Also, let's fix the seed again after clearing the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_ih3wEU9wIk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lT6o3TIKuCtk"
   },
   "source": [
    "### **Second Model Architecture**\n",
    "- Write a function that returns a sequential model with the following architecture:\n",
    " - First hidden layer with **256 nodes and the relu activation** and the **input shape = (1024, )**\n",
    " - Second hidden layer with **128 nodes and the relu activation**\n",
    " - Add the **Dropout layer with the rate equal to 0.2**\n",
    " - Third hidden layer with **64 nodes and the relu activation**\n",
    " - Fourth hidden layer with **64 nodes and the relu activation**\n",
    " - Fifth hidden layer with **32 nodes and the relu activation**\n",
    " - Add the **BatchNormalization layer**\n",
    " - Output layer with **activation as 'softmax' and number of nodes equal to the number of classes, i.e., 10**\n",
    " -Compile the model with the **loss equal to categorical_crossentropy, optimizer equal to Adam(learning_rate = 0.0005), and metric equal to 'accuracy'**. Do not fit the model here, just return the compiled model.\n",
    "- Call the nn_model_2 function and store the model in a new variable.\n",
    "- Print the summary of the model.\n",
    "- Fit on the train data with a **validation split of 0.2, batch size = 128, verbose = 1, and epochs = 30**. Store the model building history to use later for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-ZjNBmH0XIV"
   },
   "source": [
    "### **Build and train the new ANN model as per the above mentioned architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEPYLFIPnSDP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJYsvjmw0XIX"
   },
   "source": [
    "### **Plot the Training and Validation Accuracies and write down your Observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01ig6BrF1KVy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPW1LlD61RDn"
   },
   "source": [
    "**Observations:_______**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kuXx9Bvu00f"
   },
   "source": [
    "## **Predictions on the test data**\n",
    "\n",
    "- Make predictions on the test set using the second model.\n",
    "- Print the obtained results using the classification report and the confusion matrix.\n",
    "- Final observations on the obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbWMEtTj5Ad0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3li8Ib08yts"
   },
   "source": [
    "**Note:** Earlier, we noticed that each entry of the target variable is a one-hot encoded vector but to print the classification report and confusion matrix, we must convert each entry of y_test to a single label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NByu7uAQ8x9P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_SIoopr0XIg"
   },
   "source": [
    "### **Print the classification report and the confusion matrix for the test predictions. Write your observations on the final results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRddeJ-3EHT1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjErl4GA2u9s"
   },
   "source": [
    "**Final Observations:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkR4JioMsuIV"
   },
   "source": [
    "## **Using Convolutional Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YN2YgkGL_6xQ"
   },
   "source": [
    "### **Load the dataset again and split the data into the train and the test dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqM204HbAjP2",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fPqF_xGAjQB"
   },
   "source": [
    "Check the number of images in the training and the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTLJZWjPAjQB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qyMiP_rAjQB"
   },
   "source": [
    "**Observation:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJndFfEVAjQG"
   },
   "source": [
    "## **Data preparation**\n",
    "\n",
    "- Print the shape and the array of pixels for the first image in the training dataset.\n",
    "- Reshape the train and the test dataset because we always have to give a 4D array as input to CNNs.\n",
    "- Normalize the train and the test dataset by dividing by 255.\n",
    "- Print the new shapes of the train and the test dataset.\n",
    "- One-hot encode the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4uXqKz1AjQG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "at30iiX1__7F"
   },
   "source": [
    "Reshape the dataset to be able to pass them to CNNs. Remember that we always have to give a 4D array as input to CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9YPwf9ysqWU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODYnoLfaAEGx"
   },
   "source": [
    "Normalize inputs from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOGLAn40AjQG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cS9T4HqjAoyM"
   },
   "source": [
    "Print New shape of Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qf8S5NQAjQG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10QaOV-xR7Jn"
   },
   "source": [
    "### **One-hot encode the labels in the target variable y_train and y_test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KHWFWKMAjQH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-8jYVQTAjQH"
   },
   "source": [
    "**Observation:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vjx_LI4_AjQH"
   },
   "source": [
    "## **Model Building**\n",
    "\n",
    "Now that we have done data preprocessing, let's build a CNN model.\n",
    "Fix the seed for random number generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZY5pyF4-KDNt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JUAczhzAjQH"
   },
   "source": [
    "### **Model Architecture**\n",
    "- **Write a function** that returns a sequential model with the following architecture:\n",
    " - First Convolutional layer with **16 filters and the kernel size of 3x3**. Use the **'same' padding** and provide the **input shape = (32, 32, 1)**\n",
    " - Add a **LeakyRelu layer** with the **slope equal to 0.1**\n",
    " - Second Convolutional layer with **32 filters and the kernel size of 3x3 with 'same' padding**\n",
    " - Another **LeakyRelu** with the **slope equal to 0.1**\n",
    " - A **max-pooling layer** with a **pool size of 2x2**\n",
    " - **Flatten** the output from the previous layer\n",
    " - Add a **dense layer with 32 nodes**\n",
    " - Add a **LeakyRelu layer with the slope equal to 0.1**\n",
    " - Add the final **output layer with nodes equal to the number of classes, i.e., 10** and **'softmax' as the activation function**\n",
    " - Compile the model with the **loss equal to categorical_crossentropy, optimizer equal to Adam(learning_rate = 0.001), and metric equal to 'accuracy'**. Do not fit the model here, just return the compiled model.\n",
    "- Call the function cnn_model_1 and store the output in a new variable.\n",
    "- Print the summary of the model.\n",
    "- Fit the model on the training data with a **validation split of 0.2, batch size = 32, verbose = 1, and epochs = 20**. Store the model building history to use later for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWsAd45JKDNu"
   },
   "source": [
    "### **Build and train a CNN model as per the above mentioned architecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1jOYANWAjQH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPzfIf9kKDNw"
   },
   "source": [
    "### **Plot the Training and Validation Accuracies and Write your observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07oUCr1kAjQH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6zTLyp9AjQH"
   },
   "source": [
    "**Observations:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ukvtg2eMAjQH"
   },
   "source": [
    "Let's build another model and see if we can get a better model with generalized performance.\n",
    "\n",
    "First, we need to clear the previous model's history from the Keras backend. Also, let's fix the seed again after clearing the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbKi93HTolGW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep19Jd8HAjQH"
   },
   "source": [
    "### **Second Model Architecture**\n",
    "\n",
    "- Write a function that returns a sequential model with the following architecture:\n",
    " - First Convolutional layer with **16 filters and the kernel size of 3x3**. Use the **'same' padding** and provide the **input shape = (32, 32, 1)**\n",
    " - Add a **LeakyRelu layer** with the **slope equal to 0.1**\n",
    " - Second Convolutional layer with **32 filters and the kernel size of 3x3 with 'same' padding**\n",
    " - Add **LeakyRelu** with the **slope equal to 0.1**\n",
    " - Add a **max-pooling layer** with a **pool size of 2x2**\n",
    " - Add a **BatchNormalization layer**\n",
    " - Third Convolutional layer with **32 filters and the kernel size of 3x3 with 'same' padding**\n",
    " - Add a **LeakyRelu layer with the slope equal to 0.1**\n",
    " - Fourth Convolutional layer **64 filters and the kernel size of 3x3 with 'same' padding** \n",
    " - Add a **LeakyRelu layer with the slope equal to 0.1**\n",
    " - Add a **max-pooling layer** with a **pool size of 2x2**\n",
    " - Add a **BatchNormalization layer**\n",
    " - **Flatten** the output from the previous layer\n",
    " - Add a **dense layer with 32 nodes**\n",
    " - Add a **LeakyRelu layer with the slope equal to 0.1**\n",
    " - Add a **dropout layer with the rate equal to 0.5**\n",
    " - Add the final **output layer with nodes equal to the number of classes, i.e., 10** and **'softmax' as the activation function**\n",
    " - Compile the model with the **categorical_crossentropy loss, adam optimizers (learning_rate = 0.001), and metric equal to 'accuracy'**. Do not fit the model here, just return the compiled model.\n",
    "- Call the function cnn_model_2 and store the model in a new variable.\n",
    "- Print the summary of the model.\n",
    "- Fit the model on the train data with a **validation split of 0.2, batch size = 128, verbose = 1, and epochs = 30**. Store the model building history to use later for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5IBLS1eKDNy"
   },
   "source": [
    "### **Build and train the second CNN model as per the above mentioned architecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wk9sl2UEAjQH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyhUtMy3KDN1"
   },
   "source": [
    "### **Plot the Training and Validation accuracies and write your observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVQu7uWiAjQH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qrrt0Ac3AjQH"
   },
   "source": [
    "**Observations:________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kja4SnOdAjQI"
   },
   "source": [
    "## **Predictions on the test data**\n",
    "\n",
    "- Make predictions on the test set using the second model.\n",
    "- Print the obtained results using the classification report and the confusion matrix.\n",
    "- Final observations on the obtained results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHCRwRbgKDN2"
   },
   "source": [
    "### **Make predictions on the test data using the second model.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1d-VvaLAjQI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrV1tOG0AjQI"
   },
   "source": [
    "**Note:** Earlier, we noticed that each entry of the target variable is a one-hot encoded vector, but to print the classification report and confusion matrix, we must convert each entry of y_test to a single label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUSHU9W0AjQI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVCa-ysWKDN3"
   },
   "source": [
    "### **Write your final observations on the performance of the model on the test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOMq2rCJAjQJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNN9v713AjQJ"
   },
   "source": [
    "**Final Observations:_________**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
